## TensorFlow在NLP中的使用（二）

1、声音信号

将 N 个采样点集合成一个观测单位，成为帧。通常 N 的值为 256 或 512，覆盖的时间约为 20-30ms 左右。为了避免两帧之间变化过大，因此会让两相邻帧之间有一段重叠区域。通常语音识别所采用的语音信号的采样频率为 8KHz 或 16KHz。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012145910.png)

2、梅尔频率倒谱系数（MFCC）

MFCC 是一种广泛使用的语音特征，在 1980 年由 Davis 和 Mermelstein 研究出来。

3、声谱图

语音被分为很多帧，每帧语音都对应于一个频谱（通过 FFT 计算得到），频谱表示频率与能量的关
系。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150052.png)

4、频谱图

我们先将一帧语音的频谱通过坐标表示出来，如左图。再将图旋转90度，如中间的图。然后把这些幅度映射到一个灰度级表示。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150136.png)

5、spectrogram声谱图

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150208.png)

6、共振峰

下面是一个语音的频谱图。峰值就表示语音的主要频率成分，这些峰值成为共振峰。共振峰携带了声音的辨识属性。用它就可以识别不同的声音。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150244.png)

7、包络

我们需要把共振峰提取出来，不仅要提取共振峰的位置，还要提取它们转变的过程，也就是频谱的包络。包络就是一条连接这些共振峰点的平滑曲线。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150331.png)

8、分离包络和频谱的细节

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150401.png)

9、Mel频率分析

刚刚我们得到了频谱包络，不过人类听觉感知实验表明，人类的听觉的感知只聚焦在某些特定的区域，而不是整个频谱包络。Mel 频率分析就是基于人类听觉感知实验的。人耳就像一个滤波器组，它只关注某些特定频率的分量，也就是说它只让某些频率的信号通过。并且在低频区域由很多的滤波器，分布比较密集，在高频区域，滤波器比较少，也比较稀疏。

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150452.png)

10、Mel频率分析

人的听觉系统是一个特殊的非线性系统，它响应不同频率信号的灵明度是不同的。在语音特征的提取上，人类的听觉系统非常好，它不仅能提取出语义信息，而且能提取出说话人的个人特征。所以语音识别系统中能模拟人类听觉感知处理的特点，就有可能提高语音的识别率。

MFCC 考虑到了人类的听觉特征，将线性频谱映射到基于听觉感知的Mel非线性频谱中。

11、语音处理流程

![](https://img-1256179949.cos.ap-shanghai.myqcloud.com/20181012150554.png)

12、ffmpeg

- `conda install -c conda-forge ffmpeg`
- Windows 安装方式：http://www.bubuko.com/infodetail-786878.html
- Ubuntu 安装方式：http://blog.csdn.net/u012386199/article/details/51188988